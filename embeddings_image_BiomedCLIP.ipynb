{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/etowah/projects/forks/spec-image-embeddings/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "# get the model and tokenizer \n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 to 50 of 7296\n",
      "Processing 50 to 100 of 7296\n",
      "Processing 100 to 150 of 7296\n",
      "Processing 150 to 200 of 7296\n",
      "Processing 200 to 250 of 7296\n",
      "Processing 250 to 300 of 7296\n",
      "Processing 300 to 350 of 7296\n",
      "Processing 350 to 400 of 7296\n",
      "Processing 400 to 450 of 7296\n",
      "Processing 450 to 500 of 7296\n",
      "Processing 500 to 550 of 7296\n",
      "Processing 550 to 600 of 7296\n",
      "Processing 600 to 650 of 7296\n",
      "Processing 650 to 700 of 7296\n",
      "Processing 700 to 750 of 7296\n",
      "Processing 750 to 800 of 7296\n",
      "Processing 800 to 850 of 7296\n",
      "Processing 850 to 900 of 7296\n",
      "Processing 900 to 950 of 7296\n",
      "Processing 950 to 1000 of 7296\n",
      "Processing 1000 to 1050 of 7296\n",
      "Processing 1050 to 1100 of 7296\n",
      "Processing 1100 to 1150 of 7296\n",
      "Processing 1150 to 1200 of 7296\n",
      "Processing 1200 to 1250 of 7296\n",
      "Processing 1250 to 1300 of 7296\n",
      "Processing 1300 to 1350 of 7296\n",
      "Processing 1350 to 1400 of 7296\n",
      "Processing 1400 to 1450 of 7296\n",
      "Processing 1450 to 1500 of 7296\n",
      "Processing 1500 to 1550 of 7296\n",
      "Processing 1550 to 1600 of 7296\n",
      "Processing 1600 to 1650 of 7296\n",
      "Processing 1650 to 1700 of 7296\n",
      "Processing 1700 to 1750 of 7296\n",
      "Processing 1750 to 1800 of 7296\n",
      "Processing 1800 to 1850 of 7296\n",
      "Processing 1850 to 1900 of 7296\n",
      "Processing 1900 to 1950 of 7296\n",
      "Processing 1950 to 2000 of 7296\n",
      "Processing 2000 to 2050 of 7296\n",
      "Processing 2050 to 2100 of 7296\n",
      "Processing 2100 to 2150 of 7296\n",
      "Processing 2150 to 2200 of 7296\n",
      "Processing 2200 to 2250 of 7296\n",
      "Processing 2250 to 2300 of 7296\n",
      "Processing 2300 to 2350 of 7296\n",
      "Processing 2350 to 2400 of 7296\n",
      "Processing 2400 to 2450 of 7296\n",
      "Processing 2450 to 2500 of 7296\n",
      "Processing 2500 to 2550 of 7296\n",
      "Processing 2550 to 2600 of 7296\n",
      "Processing 2600 to 2650 of 7296\n",
      "Processing 2650 to 2700 of 7296\n",
      "Processing 2700 to 2750 of 7296\n",
      "Processing 2750 to 2800 of 7296\n",
      "Processing 2800 to 2850 of 7296\n",
      "Processing 2850 to 2900 of 7296\n",
      "Processing 2900 to 2950 of 7296\n",
      "Processing 2950 to 3000 of 7296\n",
      "Processing 3000 to 3050 of 7296\n",
      "Processing 3050 to 3100 of 7296\n",
      "Processing 3100 to 3150 of 7296\n",
      "Processing 3150 to 3200 of 7296\n",
      "Processing 3200 to 3250 of 7296\n",
      "Processing 3250 to 3300 of 7296\n",
      "Processing 3300 to 3350 of 7296\n",
      "Processing 3350 to 3400 of 7296\n",
      "Processing 3400 to 3450 of 7296\n",
      "Processing 3450 to 3500 of 7296\n",
      "Processing 3500 to 3550 of 7296\n",
      "Processing 3550 to 3600 of 7296\n",
      "Processing 3600 to 3650 of 7296\n",
      "Processing 3650 to 3700 of 7296\n",
      "Processing 3700 to 3750 of 7296\n",
      "Processing 3750 to 3800 of 7296\n",
      "Processing 3800 to 3850 of 7296\n",
      "Processing 3850 to 3900 of 7296\n",
      "Processing 3900 to 3950 of 7296\n",
      "Processing 3950 to 4000 of 7296\n",
      "Processing 4000 to 4050 of 7296\n",
      "Processing 4050 to 4100 of 7296\n",
      "Processing 4100 to 4150 of 7296\n",
      "Processing 4150 to 4200 of 7296\n",
      "Processing 4200 to 4250 of 7296\n",
      "Processing 4250 to 4300 of 7296\n",
      "Processing 4300 to 4350 of 7296\n",
      "Processing 4350 to 4400 of 7296\n",
      "Processing 4400 to 4450 of 7296\n",
      "Processing 4450 to 4500 of 7296\n",
      "Processing 4500 to 4550 of 7296\n",
      "Processing 4550 to 4600 of 7296\n",
      "Processing 4600 to 4650 of 7296\n",
      "Processing 4650 to 4700 of 7296\n",
      "Processing 4700 to 4750 of 7296\n",
      "Processing 4750 to 4800 of 7296\n",
      "Processing 4800 to 4850 of 7296\n",
      "Processing 4850 to 4900 of 7296\n",
      "Processing 4900 to 4950 of 7296\n",
      "Processing 4950 to 5000 of 7296\n",
      "Processing 5000 to 5050 of 7296\n",
      "Processing 5050 to 5100 of 7296\n",
      "Processing 5100 to 5150 of 7296\n",
      "Processing 5150 to 5200 of 7296\n",
      "Processing 5200 to 5250 of 7296\n",
      "Processing 5250 to 5300 of 7296\n",
      "Processing 5300 to 5350 of 7296\n",
      "Processing 5350 to 5400 of 7296\n",
      "Processing 5400 to 5450 of 7296\n",
      "Processing 5450 to 5500 of 7296\n",
      "Processing 5500 to 5550 of 7296\n",
      "Processing 5550 to 5600 of 7296\n",
      "Processing 5600 to 5650 of 7296\n",
      "Processing 5650 to 5700 of 7296\n",
      "Processing 5700 to 5750 of 7296\n",
      "Processing 5750 to 5800 of 7296\n",
      "Processing 5800 to 5850 of 7296\n",
      "Processing 5850 to 5900 of 7296\n",
      "Processing 5900 to 5950 of 7296\n",
      "Processing 5950 to 6000 of 7296\n",
      "Processing 6000 to 6050 of 7296\n",
      "Processing 6050 to 6100 of 7296\n",
      "Processing 6100 to 6150 of 7296\n",
      "Processing 6150 to 6200 of 7296\n",
      "Processing 6200 to 6250 of 7296\n",
      "Processing 6250 to 6300 of 7296\n",
      "Processing 6300 to 6350 of 7296\n",
      "Processing 6350 to 6400 of 7296\n",
      "Processing 6400 to 6450 of 7296\n",
      "Processing 6450 to 6500 of 7296\n",
      "Processing 6500 to 6550 of 7296\n",
      "Processing 6550 to 6600 of 7296\n",
      "Processing 6600 to 6650 of 7296\n",
      "Processing 6650 to 6700 of 7296\n",
      "Processing 6700 to 6750 of 7296\n",
      "Processing 6750 to 6800 of 7296\n",
      "Processing 6800 to 6850 of 7296\n",
      "Processing 6850 to 6900 of 7296\n",
      "Processing 6900 to 6950 of 7296\n",
      "Processing 6950 to 7000 of 7296\n",
      "Processing 7000 to 7050 of 7296\n",
      "Processing 7050 to 7100 of 7296\n",
      "Processing 7100 to 7150 of 7296\n",
      "Processing 7150 to 7200 of 7296\n",
      "Processing 7200 to 7250 of 7296\n",
      "Processing 7250 to 7300 of 7296\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "\n",
    "template = 'this is a photo of '\n",
    "labels = [\n",
    "    'genomics visualization',\n",
    "    'gene schematic',\n",
    "    'lollipop plot',\n",
    "    'manhattan plot',\n",
    "    'umap',\n",
    "    'pca',\n",
    "    'pie chart',\n",
    "    'heatmap',\n",
    "    'line graph',\n",
    "    'histogram',\n",
    "    'box plot',\n",
    "    'violin plot',\n",
    "    'scatter plot',\n",
    "    'bar plot',\n",
    "    'stacked bar chart',\n",
    "    'dot plot',\n",
    "    'bubble chart',\n",
    "    'network diagram',\n",
    "    'phylogenetic tree',\n",
    "    'flow chart',\n",
    "    'venn diagram',\n",
    "    'upset plot',\n",
    "    'sankey diagram',\n",
    "    'circos plot',\n",
    "    'aligned peaks',\n",
    "    'mutation signature',\n",
    "    'plant',\n",
    "    'western blot',\n",
    "    'sashimi plot',\n",
    "    'volcano plot',\n",
    "    'flow cytometry visualization',\n",
    "    'sanger trace',\n",
    "    'dose-response curve',\n",
    "    'Kaplan–Meier curves',\n",
    "    'stained cells',\n",
    "    'gel electrophoresis',\n",
    "    'gene enrichment',\n",
    "    'sequence logos',\n",
    "    'multiple seqeunce alignment',\n",
    "    'circular genomic visualization',\n",
    "    'bam pileup',\n",
    "    'treatment conditions',\n",
    "    'protein structure',\n",
    "    'table'\n",
    "]\n",
    "\n",
    "# set the directory where the images are\n",
    "image_folder = \"screenshots\"\n",
    "test_imgs = [\n",
    "    os.path.join(image_folder, file)\n",
    "    for file in os.listdir(image_folder)\n",
    "    if file.endswith((\".png\", \".jpg\", \".gif\"))\n",
    "]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "context_length = 256\n",
    "batch_size = 50\n",
    "\n",
    "# this will store the top label for each image\n",
    "top_label = []\n",
    "# this will store the embeddings of each image\n",
    "clip_embeddings = torch.Tensor()\n",
    "\n",
    "\n",
    "for i in range(0, len(test_imgs), batch_size):\n",
    "    print(f\"Processing {i} to {i+batch_size} of {len(test_imgs)}\")\n",
    "    if i + batch_size > len(test_imgs):\n",
    "        batch_size = len(test_imgs) - i\n",
    "    batch = test_imgs[i:i+batch_size]\n",
    "    images = torch.stack([preprocess_val(Image.open(img)) for img in batch]).to(device)\n",
    "    texts = tokenizer([template + l for l in labels], context_length=context_length).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features, text_features, logit_scale = model(images, texts)\n",
    "\n",
    "        logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "        sorted_indices = torch.argsort(logits, dim=-1, descending=True)\n",
    "        clip_embeddings = torch.cat((clip_embeddings, image_features / image_features.norm(dim=-1, keepdim=True)))\n",
    "\n",
    "        logits = logits.cpu().numpy()\n",
    "        sorted_indices = sorted_indices.cpu().numpy()\n",
    "        top = [labels[i] for i in sorted_indices[:, 0]]\n",
    "        top_label += top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>top_label</th>\n",
       "      <th>clip_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>screenshots/heatmap_sw_1_2_s_1_0.png</td>\n",
       "      <td>heatmap</td>\n",
       "      <td>[0.022331731, 0.007818277, -0.16542432, 0.0080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>screenshots/two_by_two_p_4_m_10_sw_0_7_s_1_2.png</td>\n",
       "      <td>genomics visualization</td>\n",
       "      <td>[0.019216416, 0.03744839, -0.12684523, -0.0058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>screenshots/multiple_view_p_2_m_12_sw_0_7_s_0_...</td>\n",
       "      <td>circular genomic visualization</td>\n",
       "      <td>[-0.0016217616, -0.051115554, -0.07445832, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>screenshots/two_by_two_uneven_w_m_20_sw_0_7_s_...</td>\n",
       "      <td>genomics visualization</td>\n",
       "      <td>[-0.0015807527, 0.038776863, -0.13082261, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>screenshots/multiple_view_p_1_m_8_sw_1_2_s_1_0...</td>\n",
       "      <td>circular genomic visualization</td>\n",
       "      <td>[-0.002367256, -0.0421267, -0.04676023, -0.033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7291</th>\n",
       "      <td>screenshots/three_composite_v_p_0_m_0_sw_1_2_s...</td>\n",
       "      <td>dot plot</td>\n",
       "      <td>[0.039080445, 0.014055151, -0.1260775, -0.0130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7292</th>\n",
       "      <td>screenshots/two_by_two_uneven_h_p_0_sw_0_7_s_1...</td>\n",
       "      <td>genomics visualization</td>\n",
       "      <td>[0.025236, 0.035443608, -0.09266704, -0.011160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293</th>\n",
       "      <td>screenshots/three_composite_m_9_sw_0_7_s_1_2.png</td>\n",
       "      <td>genomics visualization</td>\n",
       "      <td>[0.0100230975, -0.0006275425, -0.14095412, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7294</th>\n",
       "      <td>screenshots/multi_view_link_p_0_m_11_sw_1_0_s_...</td>\n",
       "      <td>circular genomic visualization</td>\n",
       "      <td>[-0.026482897, -0.019669285, -0.04968637, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>screenshots/multiple_view_p_3_m_13_sw_1_2_s_1_...</td>\n",
       "      <td>circular genomic visualization</td>\n",
       "      <td>[0.010469665, -0.04382261, -0.058548458, -0.01...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7296 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "0                  screenshots/heatmap_sw_1_2_s_1_0.png   \n",
       "1      screenshots/two_by_two_p_4_m_10_sw_0_7_s_1_2.png   \n",
       "2     screenshots/multiple_view_p_2_m_12_sw_0_7_s_0_...   \n",
       "3     screenshots/two_by_two_uneven_w_m_20_sw_0_7_s_...   \n",
       "4     screenshots/multiple_view_p_1_m_8_sw_1_2_s_1_0...   \n",
       "...                                                 ...   \n",
       "7291  screenshots/three_composite_v_p_0_m_0_sw_1_2_s...   \n",
       "7292  screenshots/two_by_two_uneven_h_p_0_sw_0_7_s_1...   \n",
       "7293   screenshots/three_composite_m_9_sw_0_7_s_1_2.png   \n",
       "7294  screenshots/multi_view_link_p_0_m_11_sw_1_0_s_...   \n",
       "7295  screenshots/multiple_view_p_3_m_13_sw_1_2_s_1_...   \n",
       "\n",
       "                           top_label  \\\n",
       "0                            heatmap   \n",
       "1             genomics visualization   \n",
       "2     circular genomic visualization   \n",
       "3             genomics visualization   \n",
       "4     circular genomic visualization   \n",
       "...                              ...   \n",
       "7291                        dot plot   \n",
       "7292          genomics visualization   \n",
       "7293          genomics visualization   \n",
       "7294  circular genomic visualization   \n",
       "7295  circular genomic visualization   \n",
       "\n",
       "                                        clip_embeddings  \n",
       "0     [0.022331731, 0.007818277, -0.16542432, 0.0080...  \n",
       "1     [0.019216416, 0.03744839, -0.12684523, -0.0058...  \n",
       "2     [-0.0016217616, -0.051115554, -0.07445832, -0....  \n",
       "3     [-0.0015807527, 0.038776863, -0.13082261, 0.05...  \n",
       "4     [-0.002367256, -0.0421267, -0.04676023, -0.033...  \n",
       "...                                                 ...  \n",
       "7291  [0.039080445, 0.014055151, -0.1260775, -0.0130...  \n",
       "7292  [0.025236, 0.035443608, -0.09266704, -0.011160...  \n",
       "7293  [0.0100230975, -0.0006275425, -0.14095412, -0....  \n",
       "7294  [-0.026482897, -0.019669285, -0.04968637, -0.0...  \n",
       "7295  [0.010469665, -0.04382261, -0.058548458, -0.01...  \n",
       "\n",
       "[7296 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data  = {\n",
    "    \"image\": test_imgs,\n",
    "    \"top_label\": top_label,\n",
    "    \"clip_embeddings\": list(clip_embeddings.cpu().numpy())\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"embeddings/biomedclip_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload embeddings to Nomic Atlas \n",
    "\n",
    "This is a visualization tool for embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-04 17:40:54.042\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_create_project\u001b[0m:\u001b[36m897\u001b[0m - \u001b[1mCreating dataset `analytical-ride`\u001b[0m\n",
      "\u001b[32m2024-04-04 17:40:54.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mUploading data to Atlas.\u001b[0m\n",
      "1it [00:06,  6.94s/it]\n",
      "\u001b[32m2024-04-04 17:41:01.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36m_add_data\u001b[0m:\u001b[36m1567\u001b[0m - \u001b[1mUpload succeeded.\u001b[0m\n",
      "\u001b[32m2024-04-04 17:41:01.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.atlas\u001b[0m:\u001b[36mmap_data\u001b[0m:\u001b[36m123\u001b[0m - \u001b[1m`quackmires/analytical-ride`: Data upload succeeded to dataset`\u001b[0m\n",
      "\u001b[32m2024-04-04 17:41:01.739\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[33m\u001b[1mYou did not specify the `topic_label_field` option in your topic_model, your dataset will not contain auto-labeled topics.\u001b[0m\n",
      "\u001b[32m2024-04-04 17:41:02.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.dataset\u001b[0m:\u001b[36mcreate_index\u001b[0m:\u001b[36m1276\u001b[0m - \u001b[1mCreated map `analytical-ride` in dataset `quackmires/analytical-ride`: https://atlas.nomic.ai/data/quackmires/analytical-ride/map\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from nomic import atlas\n",
    "\n",
    "paper_ids = [name.split(\"/\")[-1].split(\"_\")[0] for name in test_imgs]\n",
    "dataset = atlas.map_data(\n",
    "    data=[{\"name\": name, \"paper\": paper, \"classification\": label} for name, paper, label in zip(test_imgs, paper_ids, top_label)], id_field=\"name\", embeddings=np.array(clip_embeddings)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ids = [name.split(\"/\")[-1].split(\"_\")[0] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43membeddings\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
